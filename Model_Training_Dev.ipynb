{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries and load dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# load the Dataset and fill the X and Y values\n",
    "#boston = load_boston()\n",
    "#sys.path[\"D:\\\\Germany\\\\Semester 3\\\\Economic Modeling\\\\Projects\\\\SP_ESG_Pred\\\\data\\\\model_training_filesimputed_with_outliers.csv\"]\n",
    "file = pd.read_csv(\"imputed_with_outliers.csv\")\n",
    "columns_selected = [\n",
    "   'Total Current Assets', 'Total Current Liabilities',\n",
    "       'Total Debt', 'Total Assets, Reported', 'Net Income - Actual',\n",
    "       'Revenue Per Share', 'Total Revenue', 'Total Equity',\n",
    "       'Total CO2 Equivalent Emissions To Revenues USD in million',\n",
    "       'Company Market Capitalization',\n",
    "       'Property Plant And Equipment, Total - Gross',\n",
    "       'P/E (Daily Time Series Ratio)', 'returns_yearly'\n",
    "]\n",
    "X = file[columns_selected]\n",
    "y = file['ESG Score']\n",
    "\n",
    "# rescale the features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# apply scaler() to all the numeric columns \n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "#Linear Regression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# initialize the ensemble regression models\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "ab = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "bg = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# stack the models and define the meta-regressor\n",
    "stack = StackingRegressor(estimators=[('rf', rf), ('gb', gb), ('ab', ab), ('bg', bg)], final_estimator=lr)\n",
    "\n",
    "# define the voting regressor\n",
    "vote = VotingRegressor(estimators=[('rf', rf), ('gb', gb), ('ab', ab), ('bg', bg)])\n",
    "\n",
    "# fit the models on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "ab.fit(X_train, y_train)\n",
    "bg.fit(X_train, y_train)\n",
    "stack.fit(X_train, y_train)\n",
    "vote.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "rf_pred = rf.predict(X_test)\n",
    "gb_pred = gb.predict(X_test)\n",
    "ab_pred = ab.predict(X_test)\n",
    "bg_pred = bg.predict(X_test)\n",
    "stack_pred = stack.predict(X_test)\n",
    "vote_pred = vote.predict(X_test)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# calculate the root mean squared error of each model\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, gb_pred))\n",
    "ab_rmse = np.sqrt(mean_squared_error(y_test, ab_pred))\n",
    "bg_rmse = np.sqrt(mean_squared_error(y_test, bg_pred))\n",
    "stack_rmse = np.sqrt(mean_squared_error(y_test, stack_pred))\n",
    "vote_rmse = np.sqrt(mean_squared_error(y_test, vote_pred))\n",
    "\n",
    "# calculate the root mean absolute error of each model\n",
    "lr_rmae = (mean_absolute_error(y_test, lr_pred))\n",
    "rf_rmae = (mean_absolute_error(y_test, rf_pred))\n",
    "gb_rmae = (mean_absolute_error(y_test, gb_pred))\n",
    "ab_rmae = (mean_absolute_error(y_test, ab_pred))\n",
    "bg_rmae = (mean_absolute_error(y_test, bg_pred))\n",
    "stack_rmae = (mean_absolute_error(y_test, stack_pred))\n",
    "vote_rmae = (mean_absolute_error(y_test, vote_pred))\n",
    "\n",
    "\n",
    "# print the RMSE of each model\n",
    "print(\"Linear Regression RMSE:\", lr_rmse)\n",
    "print(\"Random Forest RMSE:\", rf_rmse)\n",
    "print(\"Gradient Boosting RMSE:\", gb_rmse)\n",
    "print(\"AdaBoost RMSE:\", ab_rmse)\n",
    "print(\"Bagging RMSE:\", bg_rmse)\n",
    "print(\"Stacking RMSE:\", stack_rmse)\n",
    "print(\"Voting RMSE:\", vote_rmse)\n",
    "\n",
    "\n",
    "# print the RMAE of each model\n",
    "print(\"Linear Regression RMAE:\", lr_rmae)\n",
    "print(\"Random Forest RMAE:\", rf_rmae)\n",
    "print(\"Gradient Boosting RMAE:\", gb_rmae)\n",
    "print(\"AdaBoost RMAE:\", ab_rmae)\n",
    "print(\"Bagging RMAE:\", bg_rmae)\n",
    "print(\"Stacking RMAE:\", stack_rmae)\n",
    "print(\"Voting RMAE:\", vote_rmae)\n",
    "\n",
    "# create a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "# perform cross-validation and calculate the r2_score for each model\n",
    "rf_scores = cross_val_score(rf, X, y, cv=folds, scoring='r2')\n",
    "gb_scores = cross_val_score(gb, X, y, cv=folds, scoring='r2')\n",
    "ab_scores = cross_val_score(ab, X, y, cv=folds, scoring='r2')\n",
    "bg_scores = cross_val_score(bg, X, y, cv=folds, scoring='r2')\n",
    "stack_scores = cross_val_score(stack, X, y, cv=folds, scoring='r2')\n",
    "vote_scores = cross_val_score(vote, X, y, cv=folds, scoring='r2')\n",
    "lr_scores = cross_val_score(lr, X, y, cv=folds, scoring='r2')\n",
    "\n",
    "# print the r2_score of each model\n",
    "print(\"Random Forest r2_score:\", np.mean(rf_scores))\n",
    "print(\"Gradient Boosting r2_score:\", np.mean(gb_scores))\n",
    "print(\"AdaBoost r2_score:\", np.mean(ab_scores))\n",
    "print(\"Bagging r2_score:\", np.mean(bg_scores))\n",
    "print(\"Stacking r2_score:\", np.mean(stack_scores))\n",
    "print(\"Voting r2_score:\", np.mean(vote_scores))\n",
    "print(\"Linear r2_score:\", np.mean(lr_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries and load dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# load the Dataset and fill the X and Y values\n",
    "file = pd.read_csv(\"imputed_with_outliers.csv\")\n",
    "columns_selected = [\n",
    "   'Total Current Assets', 'Total Current Liabilities',\n",
    "       'Total Debt', 'Total Assets, Reported', 'Net Income - Actual',\n",
    "       'Revenue Per Share', 'Total Revenue', 'Total Equity',\n",
    "       'Total CO2 Equivalent Emissions To Revenues USD in million',\n",
    "       'Company Market Capitalization',\n",
    "       'Property Plant And Equipment, Total - Gross',\n",
    "       'P/E (Daily Time Series Ratio)', 'returns_yearly'\n",
    "]\n",
    "X = file[columns_selected]\n",
    "y = file['ESG Score']\n",
    "\n",
    "# rescale the features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# apply scaler() to all the numeric columns \n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# define the hyperparameter grid for each model\n",
    "rf_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}\n",
    "#gb_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15], 'learning_rate': [0.1, 0.5, 1.0]}\n",
    "#ab_param_grid = {'n_estimators': [50, 100, 200], 'learning_rate': [0.1, 0.5, 1.0]}\n",
    "#bg_param_grid = {'n_estimators': [50, 100, 200], 'max_samples': [0.5, 0.8, 1.0]}\n",
    "#stack_param_grid = {\n",
    " #   'final_estimator__fit_intercept': [True, False],\n",
    "  #  'final_estimator__normalize': [True, False]\n",
    "#}\n",
    "\n",
    "#vote_param_grid = {\n",
    "#    'weights': [[1, 1, 1, 1, 1], [1, 2, 1, 1, 1], [1, 1, 2, 1, 1], [1, 1, 1, 2, 1], [1, 1, 1, 1, 2]],\n",
    "#}\n",
    "# perform hyperparameter tuning using GridSearchCV for each model\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=5, scoring='r2')\n",
    "#rf_grid1 = GridSearchCV(rf, rf_param_grid, cv=5, scoring='rmse')\n",
    "\n",
    "#gb_grid = GridSearchCV(gb, gb_param_grid, cv=5, scoring='r2')\n",
    "\n",
    "\n",
    "#ab_grid = GridSearchCV(ab, ab_param_grid, cv=5, scoring='r2')\n",
    "\n",
    "\n",
    "#bg_grid = GridSearchCV(bg, bg_param_grid, cv=5, scoring='r2')\n",
    "\n",
    "\n",
    "#stack_grid = GridSearchCV(stack, stack_param_grid, cv=5, scoring='r2')\n",
    "\n",
    "\n",
    "#vote_grid = GridSearchCV(vote, vote_param_grid, cv=5, scoring='r2')\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# fit the models on the training data\n",
    "rf_grid.fit(X_train, y_train)\n",
    "#gb_grid.fit(X_train, y_train)\n",
    "#ab_grid.fit(X_train, y_train)\n",
    "#bg_grid.fit(X_train, y_train)\n",
    "#stack_grid.fit(X_train, y_train)\n",
    "#vote_grid.fit(X_train, y_train)\n",
    "#lr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "rf_pred = rf_grid.predict(X_test)\n",
    "#gb_pred = gb_grid.predict(X_test)\n",
    "#ab_pred = ab_grid.predict(X_test)\n",
    "#bg_pred = bg_grid.predict(X_test)\n",
    "#stack_pred = stack_grid.predict(X_test)\n",
    "#vote_pred = vote_grid.predict(X_test)\n",
    "#lr_pred = lr.predict(X_test)\n",
    "\n",
    "# calculate the root mean squared error of each model\n",
    "#lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "#gb_rmse = np.sqrt(mean_squared_error(y_test, gb_pred))\n",
    "#ab_rmse = np.sqrt(mean_squared_error(y_test, ab_pred))\n",
    "bg_rmse = np.sqrt(mean_squared_error(y_test, bg_pred))\n",
    "#stack_rmse = np.sqrt(mean_squared_error(y_test, stack_pred))\n",
    "#vote_rmse = np.sqrt(mean_squared_error(y_test, vote_pred))\n",
    "\n",
    "# calculate the root mean absolute error of each model\n",
    "#lr_rmae = (mean_absolute_error(y_test, lr_pred))\n",
    "rf_rmae = (mean_absolute_error(y_test, rf_pred))\n",
    "# gb_rmae = (mean_absolute_error(y_test, gb_pred))\n",
    "# ab_rmae = (mean_absolute_error(y_test, ab_pred))\n",
    "# bg_rmae = (mean_absolute_error(y_test, bg_pred))\n",
    "#stack_rmae = (mean_absolute_error(y_test, stack_pred))\n",
    "#vote_rmae = (mean_absolute_error(y_test, vote_pred))\n",
    "\n",
    "\n",
    "# print the RMSE of each model\n",
    "#print(\"Linear Regression RMSE:\", lr_rmse)\n",
    "print(\"Random Forest RMSE:\", rf_rmse)\n",
    "# print(\"Gradient Boosting RMSE:\", gb_rmse)\n",
    "# print(\"AdaBoost RMSE:\", ab_rmse)\n",
    "# print(\"Bagging RMSE:\", bg_rmse)\n",
    "#print(\"Stacking RMSE:\", stack_rmse)\n",
    "#print(\"Voting RMSE:\", vote_rmse)\n",
    "\n",
    "\n",
    "# print the RMAE of each model\n",
    "#print(\"Linear Regression RMAE:\", lr_rmae)\n",
    "print(\"Random Forest RMAE:\", rf_rmae)\n",
    "# print(\"Gradient Boosting RMAE:\", gb_rmae)\n",
    "# print(\"AdaBoost RMAE:\", ab_rmae)\n",
    "# print(\"Bagging RMAE:\", bg_rmae)\n",
    "#print(\"Stacking RMAE:\", stack_rmae)\n",
    "#print(\"Voting RMAE:\", vote_rmae)\n",
    "\n",
    "# create a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "# perform cross-validation and calculate the r2_score for each model\n",
    "#rf_scores = cross_val_score(rf, X, y, cv=folds, scoring='r2')\n",
    "#gb_scores = cross_val_score(gb, X, y, cv=folds, scoring='r2')\n",
    "#ab_scores = cross_val_score(ab, X, y, cv=folds, scoring='r2')\n",
    "#bg_scores = cross_val_score(bg, X, y, cv=folds, scoring='r2')\n",
    "#stack_scores = cross_val_score(stack, X, y, cv=folds, scoring='r2')\n",
    "#vote_scores = cross_val_score(vote, X, y, cv=folds, scoring='r2')\n",
    "#lr_scores = cross_val_score(lr, X, y, cv=folds, scoring='r2')\n",
    "\n",
    "# print the r2_score of each model\n",
    "print(\"Random Forest Regression best parameters:\", rf_grid.best_params_)\n",
    "print(\"Random Forest Regression r2_score:\", rf_grid.best_score_)\n",
    "# print(\"Gradient Boosting Regression best parameters:\", gb_grid.best_params_)\n",
    "# print(\"Gradient Boosting Regression r2_score:\", gb_grid.best_score_)\n",
    "# print(\"AdaBoost Regression best parameters:\", ab_grid.best_params_)\n",
    "# print(\"AdaBoost Regression r2_score:\", ab_grid.best_score_)\n",
    "# print(\"Bagging Regression best parameters:\", bg_grid.best_params_)\n",
    "# print(\"Bagging Regression r2_score:\", bg_grid.best_score_)\n",
    "#print(\"Stacking Regression best parameters:\", stack_grid.best_params_)\n",
    "#print(\"Stacking Regression r2_score:\", stack_grid.best_score_)\n",
    "#print(\"Voting Regression best parameters:\", vote_grid.best_params_)\n",
    "#print(\"Voting Regression r2_score:\", vote_grid.best_score_)\n",
    "#print(\"Linear r2_score:\", np.mean(lr_scores))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
